---
title: '笔记: Design Data Intensive Applications (DDIA)'
date: 2025-10-30 15:29:54
categories:
  - dev
---

## C2: 定义非功能性需求

### 名人问题
我们希望设计一个twitter-like的社交应用，用户可以互相关注。每当一个用户发帖，我们希望将帖子推送给所有关注者。有两个解决方案
* 读扩散(fan-out on read): 每个客户端以一定时间向服务器轮训，执行一条SQL查询最新的、关注的人发布的帖子。写入时只需要插入到每个用户自己的发帖列表里。
* 写扩散(fan-out on write): 给每个用户建立一个时间线(物化视图/materialized view)，每当有人发帖，插入到所有用户的时间线中。读取时只需要获取这个时间线。

扇出(fan-out)这个词非常形象，描述的是每个用户的更新将会被扩散给许多人(他的关注/被关注)

轮询的方式显然是不高效的。但写扩散也存在问题。少部分名人拥有大量的订阅者，他们每次发帖的写入成本将非常高。于是我们可以结合两者：
* 对于普通用户，采用写扩散(平均来说最多也不过上百次的写入)
* 对于名人，采用读扩散
* 用户查询时，结合自己的时间线，和从名人表里查询到的新帖子(因为名人总数很少，所以这个表不会很大)，组合成最终的时间线

Remark: 这个优化实际上是基于大部分人只有少量的关注者，少部分人有大量的关注者这个事实。同时这也是一种"分摊"的策略: 把一次超级大的写入分摊给多次小的读取，和减少gc/哈希表扩容带来的STW有异曲同工之妙。

### 亚稳态故障(Metastable Failure)

亚稳态故障描述的是，因为诸如重试风暴(retry storm)之类的原因，系统在突发的流量激增后，本来应该逐步恢复，但实际上一直处于过载的状态无法恢复。

常见解决方法
* 指数退避(exponential backoff): 也就是TCP所使用的重试策略，每次重试之间间隔翻倍，并且用随机数来避免大量客户端同时重试形成新的波峰
* 熔断器(circuit breaker): 这个很简单，就是监控请求的状态。如果一段时间内有超过一个阈值比例的请求都出错了，直接熔断，不接受新的请求，让服务器先处理积压的请求。等一段时间后再尝试重新允许新请求。
* 令牌桶(token bucket): 系统以固定速率生成token，添加到bucket，bucket有一个最大的capacity，超出后的token直接丢弃，也就是限制了系统短时间内可以处理的最大突发请求量。每个请求的处理都消耗一个token。当桶中无token但请求到达时，直接拒绝/降级/加入等待队列。
* 负载卸除(load shedding): 即系统在监测到即将过载时拒绝请求，返回503 Service Unavailable
* 背压(backpressure): 上游告诉下游(数据发送方)降低速率

排队(queuing)和负载均衡(load balancing)算法也会造成影响

### 延迟

队头阻塞(Head-of-line blocking): 在计算机网络课程中HTTP的部分也有提到，即服务器并发性能有限，少量慢请求会使后面的所有快请求的排队时间大大增加。

通常使用百分位数来衡量系统的响应时间，中位数也是第50百分位，记为p50

尾部延迟很重要。Amazon采用p999作为衡量标准，即使1000个请求中只有1个经历了这么长的响应时间，但大概率请求最慢的客户也是数据最多的客户，非常有必要保证这部分客户对服务的满意度。同时，如果使用p9999或者更高，那么优化起来太过困难。
尾部延迟放大(Tail Latency Amplification): 单个用户可能并发多个请求，此时响应时间是由最慢的请求决定的。调用多个请求更有可能受到某一次慢调用的影响。
